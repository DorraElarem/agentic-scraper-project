#!/usr/bin/env python3
"""
Script d'analyse des rÃ©sultats de scraping amÃ©liorÃ©
Analyse les fichiers JSON de rÃ©sultats pour extraire des insights
"""

import json
import re
from typing import Dict, Any, List
from pathlib import Path

def analyze_scraping_results(json_file: str = "test_results_20250811_153353.json"):
    """Analyse dÃ©taillÃ©e des rÃ©sultats de scraping"""
    
    print("ðŸ” ANALYSE DÃ‰TAILLÃ‰E DES RÃ‰SULTATS DE SCRAPING")
    print("=" * 60)
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ðŸ“ Fichier: {json_file}")
        
        # DÃ©tecter le format des donnÃ©es
        if isinstance(data, list):
            print(f"ðŸ“Š Tests effectuÃ©s: {len(data)}")
            tests_data = data
        elif isinstance(data, dict):
            print(f"ðŸ“Š Format: Dictionnaire unique")
            tests_data = [data]
        else:
            print(f"âŒ Format de donnÃ©es non reconnu: {type(data)}")
            return False
        
        for i, test_result in enumerate(tests_data, 1):
            # Gestion des diffÃ©rents formats de test_result
            if isinstance(test_result, str):
                print(f"\nðŸ§ª TEST {i}: DonnÃ©es en format string - parsing nÃ©cessaire")
                continue
                
            if isinstance(test_result, dict):
                url = test_result.get('url', test_result.get('test_url', 'URL inconnue'))
                print(f"\nðŸ§ª TEST {i}: {url}")
                print("-" * 40)
                
                # Analyser chaque mode (STANDARD/ADVANCED)
                for mode in ['standard', 'advanced']:
                    if mode in test_result:
                        analyze_mode_results(test_result[mode], mode.upper())
                
                # Comparaison des modes
                if 'standard' in test_result and 'advanced' in test_result:
                    compare_modes(test_result['standard'], test_result['advanced'])
                
                # Si le format est diffÃ©rent, essayer d'analyser directement
                elif 'results' in test_result or 'task_id' in test_result:
                    print(f"   ðŸ“Š Format direct dÃ©tectÃ©")
                    analyze_direct_results(test_result)
    
    except FileNotFoundError:
        print(f"âŒ Fichier {json_file} non trouvÃ©")
        return False
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False
    
    return True

def analyze_mode_results(mode_data: Dict[str, Any], mode_name: str):
    """Analyse des rÃ©sultats pour un mode donnÃ©"""
    
    print(f"\nðŸ“Š MODE {mode_name}:")
    
    # Informations de base
    task_id = mode_data.get('task_id', 'N/A')
    status = mode_data.get('status', 'N/A')
    execution_time = mode_data.get('execution_time', 0)
    
    print(f"   ðŸ†” Task ID: {task_id[:8]}...")
    print(f"   âœ… Status: {status}")
    print(f"   â±ï¸ Temps: {execution_time:.1f}s")
    
    # Analyser les rÃ©sultats dÃ©taillÃ©s
    results = mode_data.get('results', {})
    if not results:
        print("   âš ï¸ Aucun rÃ©sultat dÃ©taillÃ© disponible")
        return
    
    # Compter les valeurs extraites
    extracted_values = results.get('extracted_values', {})
    key_figures = results.get('key_figures', {})
    content_length = len(results.get('content', ''))
    
    print(f"   ðŸŽ¯ Valeurs extraites: {len(extracted_values)}")
    print(f"   ðŸ”‘ Chiffres clÃ©s: {len(key_figures)}")
    print(f"   ðŸ“„ Contenu: {content_length:,} caractÃ¨res")
    
    # Analyser les types de valeurs extraites
    if extracted_values:
        analyze_extracted_values(extracted_values)
    
    # Analyser les chiffres clÃ©s
    if key_figures:
        analyze_key_figures(key_figures)
    
    # MÃ©triques de qualitÃ©
    metrics = results.get('metrics', {})
    if metrics:
        print(f"   ðŸ“ˆ MÃ©triques disponibles: {len(metrics)}")

def analyze_extracted_values(extracted_values: Dict[str, Any]):
    """Analyse dÃ©taillÃ©e des valeurs extraites"""
    
    print(f"   ðŸ“Š ANALYSE DES VALEURS EXTRAITES:")
    
    # Grouper par type/source
    sources = {}
    values_by_type = {}
    
    for key, value_data in extracted_values.items():
        # Extraire la source/mÃ©thode
        if isinstance(value_data, dict):
            source = value_data.get('source', 'unknown')
            value = value_data.get('value')
            unit = value_data.get('unit', 'no_unit')
        else:
            source = 'direct'
            value = value_data
            unit = 'no_unit'
        
        # Compter par source
        sources[source] = sources.get(source, 0) + 1
        
        # Compter par type de valeur
        if isinstance(value, (int, float)):
            if value > 1000:
                value_type = 'large_number'
            elif value < 1:
                value_type = 'decimal'
            else:
                value_type = 'standard'
        else:
            value_type = 'text'
        
        values_by_type[value_type] = values_by_type.get(value_type, 0) + 1
    
    # Afficher les statistiques
    print(f"      ðŸ” Sources d'extraction:")
    for source, count in sources.items():
        print(f"         â€¢ {source}: {count} valeurs")
    
    print(f"      ðŸ“ˆ Types de valeurs:")
    for value_type, count in values_by_type.items():
        print(f"         â€¢ {value_type}: {count} valeurs")
    
    # Montrer quelques exemples
    print(f"      ðŸ“ Exemples (5 premiers):")
    for i, (key, value_data) in enumerate(list(extracted_values.items())[:5]):
        if isinstance(value_data, dict):
            value = value_data.get('value', 'N/A')
            unit = value_data.get('unit', '')
        else:
            value = value_data
            unit = ''
        
        print(f"         {i+1}. {key}: {value} {unit}")

def analyze_key_figures(key_figures: Dict[str, Any]):
    """Analyse des chiffres clÃ©s identifiÃ©s"""
    
    print(f"   ðŸ”‘ CHIFFRES CLÃ‰S IDENTIFIÃ‰S:")
    
    categories = {}
    for key, figure_data in key_figures.items():
        if isinstance(figure_data, dict):
            category = figure_data.get('category', 'general')
            value = figure_data.get('value')
            unit = figure_data.get('unit', '')
        else:
            category = 'general'
            value = figure_data
            unit = ''
        
        if category not in categories:
            categories[category] = []
        categories[category].append({'key': key, 'value': value, 'unit': unit})
    
    for category, figures in categories.items():
        print(f"      ðŸ“Š {category}: {len(figures)} figures")
        for figure in figures[:3]:  # Montrer 3 premiers
            print(f"         â€¢ {figure['key']}: {figure['value']} {figure['unit']}")

def analyze_direct_results(test_result: Dict[str, Any]):
    """Analyse des rÃ©sultats en format direct"""
    
    print(f"   ðŸ“Š ANALYSE DIRECTE:")
    
    # Informations de base
    task_id = test_result.get('task_id', 'N/A')
    status = test_result.get('status', 'N/A')
    
    print(f"   ðŸ†” Task ID: {task_id[:8] if task_id != 'N/A' else 'N/A'}...")
    print(f"   âœ… Status: {status}")
    
    # Analyser les rÃ©sultats
    results = test_result.get('results', test_result)
    
    if isinstance(results, list) and results:
        results = results[0]  # Prendre le premier rÃ©sultat
    
    # Compter les Ã©lÃ©ments extraits
    content = results.get('content', '')
    extracted_values = results.get('extracted_values', {})
    key_figures = results.get('key_figures', {})
    
    print(f"   ðŸ“„ Contenu: {len(content):,} caractÃ¨res")
    print(f"   ðŸŽ¯ Valeurs extraites: {len(extracted_values)}")
    print(f"   ðŸ”‘ Chiffres clÃ©s: {len(key_figures)}")
    
    # Analyser les valeurs extraites
    if extracted_values:
        analyze_extracted_values(extracted_values)
    
    # Analyser les mÃ©triques
    metrics = results.get('metrics', {})
    if metrics:
        print(f"   ðŸ“ˆ MÃ©triques: {len(metrics)} disponibles")
        for metric_name, metric_value in list(metrics.items())[:5]:
            print(f"      â€¢ {metric_name}: {metric_value}")

def debug_json_structure(json_file: str):
    """Debug pour comprendre la structure du JSON"""
    
    print("\nðŸ” DEBUG - STRUCTURE DU FICHIER JSON")
    print("=" * 50)
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"ðŸ“ Type principal: {type(data)}")
        
        if isinstance(data, dict):
            print(f"ðŸ“Š ClÃ©s principales: {list(data.keys())}")
            for key, value in list(data.items())[:3]:
                print(f"   â€¢ {key}: {type(value)} ({len(str(value))} chars)")
        
        elif isinstance(data, list):
            print(f"ðŸ“Š Ã‰lÃ©ments dans la liste: {len(data)}")
            for i, item in enumerate(data[:3]):
                print(f"   [{i}] Type: {type(item)}")
                if isinstance(item, dict):
                    print(f"       ClÃ©s: {list(item.keys())}")
                elif isinstance(item, str):
                    print(f"       Longueur: {len(item)} chars")
                    print(f"       DÃ©but: {item[:100]}...")
        
        # Essayer de trouver les donnÃ©es de rÃ©sultats
        print(f"\nðŸ” Recherche de patterns de donnÃ©es:")
        json_str = json.dumps(data)
        
        patterns_to_find = [
            'extracted_values',
            'task_id', 
            'results',
            'standard',
            'advanced',
            'status'
        ]
        
        for pattern in patterns_to_find:
            if pattern in json_str:
                print(f"   âœ… TrouvÃ©: '{pattern}'")
            else:
                print(f"   âŒ Absent: '{pattern}'")
                
    except Exception as e:
        print(f"âŒ Erreur de debug: {e}")

def smart_analyze_results(json_file: str):
    """Analyse intelligente qui s'adapte au format"""
    
    print("ðŸ§  ANALYSE INTELLIGENTE DES RÃ‰SULTATS")
    print("=" * 50)
    
    try:
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Fonction rÃ©cursive pour trouver les valeurs extraites
        def find_extracted_values(obj, path=""):
            findings = []
            
            if isinstance(obj, dict):
                for key, value in obj.items():
                    current_path = f"{path}.{key}" if path else key
                    
                    if key == 'extracted_values' and isinstance(value, dict):
                        findings.append({
                            'path': current_path,
                            'count': len(value),
                            'data': value
                        })
                    elif isinstance(value, (dict, list)):
                        findings.extend(find_extracted_values(value, current_path))
            
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    current_path = f"{path}[{i}]" if path else f"[{i}]"
                    findings.extend(find_extracted_values(item, current_path))
            
            return findings
        
        # Chercher toutes les instances de valeurs extraites
        extracted_findings = find_extracted_values(data)
        
        print(f"ðŸŽ¯ Valeurs extraites trouvÃ©es: {len(extracted_findings)} instances")
        
        for i, finding in enumerate(extracted_findings):
            print(f"\nðŸ“Š Instance {i+1}: {finding['path']}")
            print(f"   Nombre de valeurs: {finding['count']}")
            
            # Analyser les premiÃ¨res valeurs
            if finding['data']:
                sample_items = list(finding['data'].items())[:5]
                print(f"   Exemples:")
                for key, value in sample_items:
                    if isinstance(value, dict):
                        val = value.get('value', value)
                        unit = value.get('unit', '')
                        print(f"      â€¢ {key}: {val} {unit}")
                    else:
                        print(f"      â€¢ {key}: {value}")
        
        # Statistiques globales
        total_values = sum(f['count'] for f in extracted_findings)
        print(f"\nðŸ“ˆ STATISTIQUES GLOBALES:")
        print(f"   ðŸŽ¯ Total des valeurs extraites: {total_values}")
        
        if total_values > 0:
            print(f"   âœ… Extraction fonctionnelle!")
            print(f"   ðŸ’¡ Le scraper fonctionne correctement")
        else:
            print(f"   âš ï¸ Aucune valeur extraite")
            print(f"   ðŸ’¡ VÃ©rifier la configuration du scraper")
            
    except Exception as e:
        print(f"âŒ Erreur d'analyse intelligente: {e}")
        import traceback
        traceback.print_exc()
    """Comparaison entre mode STANDARD et ADVANCED"""
    
    print(f"\nðŸ”„ COMPARAISON STANDARD vs ADVANCED:")
    
    # Temps d'exÃ©cution
    std_time = standard_data.get('execution_time', 0)
    adv_time = advanced_data.get('execution_time', 0)
    
    if adv_time > 0:
        speed_ratio = adv_time / std_time if std_time > 0 else float('inf')
        print(f"   â±ï¸ Vitesse: STANDARD {speed_ratio:.1f}x plus rapide")
    
    # QuantitÃ© de donnÃ©es extraites
    std_values = len(standard_data.get('results', {}).get('extracted_values', {}))
    adv_values = len(advanced_data.get('results', {}).get('extracted_values', {}))
    
    print(f"   ðŸ“Š Valeurs extraites:")
    print(f"      â€¢ STANDARD: {std_values}")
    print(f"      â€¢ ADVANCED: {adv_values}")
    
    if std_values == adv_values:
        print(f"      âœ… RÃ©sultats identiques")
    else:
        difference = abs(adv_values - std_values)
        better_mode = "ADVANCED" if adv_values > std_values else "STANDARD"
        print(f"      ðŸ“ˆ {better_mode} extrait {difference} valeurs en plus")
    
    # Recommandation
    if std_values == adv_values and std_time < adv_time:
        print(f"   ðŸ’¡ RECOMMANDATION: Utiliser le mode STANDARD (mÃªme rÃ©sultats, plus rapide)")
    elif adv_values > std_values:
        print(f"   ðŸ’¡ RECOMMANDATION: Utiliser le mode ADVANCED (plus de donnÃ©es)")
    else:
        print(f"   ðŸ’¡ RECOMMANDATION: Mode STANDARD optimal pour ce cas")

def generate_quality_score(data: Dict[str, Any]) -> float:
    """GÃ©nÃ¨re un score de qualitÃ© pour l'extraction"""
    
    score = 0.0
    max_score = 10.0
    
    # CritÃ¨res d'Ã©valuation
    criteria = {
        'execution_success': 2.0,  # TÃ¢che terminÃ©e avec succÃ¨s
        'values_extracted': 3.0,   # Nombre de valeurs extraites
        'variety_sources': 2.0,    # VariÃ©tÃ© des sources d'extraction
        'key_figures': 2.0,        # PrÃ©sence de chiffres clÃ©s
        'execution_time': 1.0      # RapiditÃ© d'exÃ©cution
    }
    
    # Ã‰valuer chaque critÃ¨re
    for mode in ['standard', 'advanced']:
        if mode in data:
            mode_data = data[mode]
            
            # SuccÃ¨s d'exÃ©cution
            if mode_data.get('status') == 'completed':
                score += criteria['execution_success'] / 2
            
            results = mode_data.get('results', {})
            
            # Valeurs extraites
            extracted_count = len(results.get('extracted_values', {}))
            if extracted_count > 0:
                # Score basÃ© sur le nombre de valeurs (max 15 = score complet)
                values_score = min(extracted_count / 15, 1.0) * criteria['values_extracted']
                score += values_score / 2
            
            # Temps d'exÃ©cution (bonus si < 10s)
            exec_time = mode_data.get('execution_time', float('inf'))
            if exec_time < 10:
                score += criteria['execution_time'] / 2
    
    return round(score, 1)

def main():
    """Fonction principale"""
    
    # Chercher le fichier de rÃ©sultats le plus rÃ©cent
    json_files = list(Path('.').glob('test_results_*.json'))
    
    if not json_files:
        print("âŒ Aucun fichier de rÃ©sultats trouvÃ©")
        return
    
    # Prendre le plus rÃ©cent
    latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
    
    print(f"ðŸ“ Analyse du fichier: {latest_file}")
    
    # D'abord faire un debug de la structure
    debug_json_structure(str(latest_file))
    
    # Puis l'analyse intelligente
    smart_analyze_results(str(latest_file))
    
    # Essayer l'analyse standard si possible
    try:
        success = analyze_scraping_results(str(latest_file))
        
        if success:
            print(f"\nðŸŽ¯ CONCLUSION GÃ‰NÃ‰RALE:")
            print(f"   âœ… SystÃ¨me de scraping opÃ©rationnel")
            print(f"   ðŸ“Š Extraction de valeurs fonctionnelle") 
            print(f"   ðŸš€ Performance satisfaisante")
            print(f"   ðŸ’¡ PrÃªt pour utilisation en production")
    except Exception as e:
        print(f"\nâš ï¸ Analyse standard Ã©chouÃ©e: {e}")
        print(f"ðŸ’¡ Utilisation de l'analyse intelligente uniquement")
    
if __name__ == "__main__":
    main()